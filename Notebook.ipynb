{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivation:\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An application of the Louvain algorithm on fMRI time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary Packages\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import Series, read_csv\n",
    "from igraph import *\n",
    "# from numba import jit\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase 1: Construction\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1:\n",
    "Concatenate time series from all subjects into a 264 x Time matrix\n",
    "where times 1-720 are from person 1, times 721 - 1441 are from person\n",
    "2, etc. through person N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gather all the files.\n",
    "files = os.listdir('timeseries/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate (or stack) all the files.\n",
    "# Approx 12.454981 seconds\n",
    "first = True\n",
    "for f in files:\n",
    "    if first == True:\n",
    "        ts_matrix = np.loadtxt('timeseries/' + f).T\n",
    "        first = False\n",
    "    else:\n",
    "        new_ts = np.loadtxt('timeseries/' + f).T\n",
    "        ts_matrix = np.hstack((ts_matrix, new_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2:\n",
    "Compute a Time x Time correlation matrix using Pearson correlation\n",
    "coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute the correlation matrix\n",
    "\"\"\"\n",
    "corr_mat = np.corrcoef(ts_matrix.T)\n",
    "\n",
    "# Save in .npz file\n",
    "# np.savez_compressed('corr_mat.npz', corr_mat=corr_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: \n",
    "Threshold the Time x Time correlation matrix to retain x% of the\n",
    "strongest connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = np.load('corr_mat.npz')\n",
    "# X = X['corr_mat']\n",
    "\n",
    "# a flatten function optimized by numba\n",
    "# @jit\n",
    "def fast_flatten(X):\n",
    "    k = 0\n",
    "    length = X.shape[0] * X.shape[1]\n",
    "    X_flat = np.empty(length)\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            X_flat[k] = X[i, j]\n",
    "            k += 1\n",
    "    return X_flat\n",
    "\n",
    "# helper function that returns the min of the number of \n",
    "# unique values depending on the threshold\n",
    "def min_thresh_val(X, threshold):\n",
    "    X_flat = fast_flatten(X)\n",
    "    index = int(len(X_flat) * threshold)\n",
    "    return np.unique(sort(X_flat))[::-1][:index].min()\n",
    "\n",
    "# Computes the threshold matrix without killing the python kernel\n",
    "# @jit\n",
    "def thresh_mat(X, threshold):\n",
    "    min_val = min_thresh_val(X, threshold)\n",
    "    print(\"Done with min_thresh_val\")\n",
    "    # M = zeros((X.shape[0], X.shape[1]))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            # if X[i, j] >= min_val:\n",
    "                # M[i, j] = X[i, j]\n",
    "            if X[i, j] < min_val:\n",
    "                X[i, j] = 0\n",
    "                \n",
    "thresh_mat(X, .01)\n",
    "print(\"Finished Threshold Matrix\")\n",
    "# savez_compressed('threshold_mat.npz', threshold_mat=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4:\n",
    "Feed the thresholded Time x Time correlation matrix into igraph to\n",
    "maximize modularity (using a community detection technique) which will\n",
    "provide us with an association of time points to brain states (a.k.a.\n",
    "modules, communities, or clusters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from: http://stackoverflow.com/questions/29655111/igraph-graph-from-numpy-or-pandas-adjacency-matrix\n",
    "\n",
    "# get the row, col indices of the non-zero elements in your adjacency matrix\n",
    "conn_indices = np.where(X)\n",
    "\n",
    "# get the weights corresponding to these indices\n",
    "weights = X[conn_indices]\n",
    "\n",
    "# a sequence of (i, j) tuples, each corresponding to an edge from i -> j\n",
    "edges = zip(*conn_indices)\n",
    "\n",
    "# initialize the undirected graph from the edge sequence\n",
    "G = Graph(edges=edges, directed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign node names and weights to be attributes of the vertices and edges\n",
    "# respectively\n",
    "G.vs['label'] = np.arange(X.shape[0])\n",
    "G.es['weight'] = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the vertex clustering corresponding to the best modularity\n",
    "cm = G.community_multilevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the cluster membership of each node in a csv file\n",
    "Series(cm.membership).to_csv('mem.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase 2: Validation\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the vector containing the list of assigned clusters at each time (0 - 46208).\n",
    "    \n",
    "Each number in the vector of cluster assignments tells you which time\n",
    "point and which subject is assigned to which cluster. So now you need\n",
    "to go back and time the original data for that time point. Remember\n",
    "that the original data you had is a vector of 264 activities for each\n",
    "time point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def index_list(num, ind_list, ts_matrix):\n",
    "    i = 0\n",
    "    for z in zip(ind_list, ts_matrix):\n",
    "        if z[0] == num and i == 0:\n",
    "            output = np.array([z[1]])\n",
    "            i += 1\n",
    "        elif z[0] == num and i != 0:\n",
    "            output = np.append(output, [z[1]], axis=0)\n",
    "    return output\n",
    "\n",
    "louvain_ind = read_csv('mem.csv').values.T\n",
    "\n",
    "\n",
    "# TODO: generalize the ranges\n",
    "for f in files:\n",
    "    ts_matrix = np.loadtxt('timeseries/' + f).T\n",
    "\n",
    "    for i in range(1, 65):\n",
    "        subject = louvain_ind[:722 * i][0]\n",
    "        for j in range(4):\n",
    "            i_list = index_list(j, subject, ts_matrix)\n",
    "            avg = np.average(i_list, axis=1)\n",
    "            Series(avg).to_csv(\"module_matrices/subject\" + str(i)\n",
    "                                + \"mod\" + str(j), index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
